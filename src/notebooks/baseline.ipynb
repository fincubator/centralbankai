{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import dill\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.transforms import rename_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/csv/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../../data/csv/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = rename_columns(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = rename_columns(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_cat = [\n",
    "    'service',\n",
    "    'priority',\n",
    "    'status',\n",
    "    'group',\n",
    "    'type_query',\n",
    "    'criticality',\n",
    "    'impact',\n",
    "    'system',\n",
    "    'place'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = feats_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../configs/features.json\", \"w\") as stream:\n",
    "    features = {\n",
    "        \"all_feat\": train_features,\n",
    "        \"feats_numeric\": [],\n",
    "        \"feats_cat\": feats_cat\n",
    "    }\n",
    "    json.dump(features, stream, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"type_reclassification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = lambda *args: f1_score(*args, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index().rename(columns={\"index\": \"ID\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in feats_cat:\n",
    "    le = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=np.nan)\n",
    "    train[feat] = le.fit_transform(train[feat].values.reshape(-1, 1))\n",
    "    with open(f\"../../objects/encoders/{feat}_enc.dill\", \"wb\") as stream:\n",
    "        dill.dump(le, stream)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"num_leaves\": 32,\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"subsample\": 0.8,\n",
    "    \"subsample_freq\": 1,\n",
    "    \"min_child_samples\": 300,\n",
    "    \"n_jobs\": 10,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"num_class\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"../../models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_cv(\n",
    "    train,\n",
    "    target,\n",
    "    train_features,\n",
    "    cat_features=None,\n",
    "    random_state=42,\n",
    "    n_folds=5,\n",
    "    model_folder=\"models\",\n",
    "    model_name=\"model\",\n",
    "    model_params=None,\n",
    "    verbose=True\n",
    "):\n",
    "    cat_feats_ind = [i for i, j in enumerate(train_features) if j in cat_features]\n",
    "    model_params[\"categorical_column\"] = cat_feats_ind\n",
    "    skf = StratifiedKFold(n_splits=n_folds, random_state=random_state, shuffle=True)\n",
    "    preds = []\n",
    "    scores = []\n",
    "    for i, (train_idx, test_idx) in enumerate(skf.split(train[train_features], train[target])):\n",
    "        X_train, y_train = train[train_features].iloc[train_idx], train[target].iloc[train_idx]\n",
    "        X_test, y_test = train[train_features].iloc[test_idx], train[target].iloc[test_idx]\n",
    "        model = lgb.LGBMModel(**model_params)\n",
    "        e_stop = round(5 / model.get_params()['learning_rate'])\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=(X_test, y_test), \n",
    "            early_stopping_rounds=e_stop,\n",
    "            eval_metric=model.metric,\n",
    "            verbose=False\n",
    "        )\n",
    "        if model_name is not None:\n",
    "            model.booster_.save_model(os.path.join(model_folder, model_name, f\"fold_{i}.model\",))\n",
    "        fold_preds = model.predict(X_test)\n",
    "        fold_labels = np.argmax(fold_preds, axis=1)\n",
    "        fold_score = metric(y_test, fold_labels)\n",
    "        preds.append(fold_preds)\n",
    "        scores.append(fold_score)\n",
    "        if verbose:\n",
    "            print(\n",
    "                i,\n",
    "                \"it:\", model.best_iteration_,\n",
    "                \"score:\", fold_score\n",
    "            )\n",
    "    return preds, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVModel():\n",
    "    import numpy as np\n",
    "    def __init__(self, models_folder, num_class=3):\n",
    "        from os import listdir\n",
    "        import lightgbm\n",
    "        model_files = [f for f in listdir(models_folder) if '.model' in f]\n",
    "\n",
    "        self.models = []\n",
    "        for model_file in model_files:             \n",
    "            self.models.append(lightgbm.Booster(model_file=os.path.join(models_folder, model_file), params={'n_jobs':1}))\n",
    "        self.num_class = num_class\n",
    "\n",
    "    def predict(self, Y):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        prediction = np.zeros((Y.shape[0], self.num_class))\n",
    "        for model in self.models:\n",
    "\n",
    "            if(isinstance(Y, pd.DataFrame)):\n",
    "                prediction += model.predict(Y[model.feature_name()])\n",
    "            else:\n",
    "                prediction += model.predict(Y)\n",
    "\n",
    "        return prediction / len(self.models)\n",
    "    \n",
    "    def predict_labels(self, Y):\n",
    "        predictions = self.predict(Y)\n",
    "        labels = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    model_params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",                \n",
    "        \"seed\": 42,\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 512),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 0, 15),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "        \"num_class\": 3\n",
    "    }\n",
    "    preds, scores = base_cv(\n",
    "        train,\n",
    "        target,\n",
    "        train_features,\n",
    "        cat_features=feats_cat,\n",
    "        model_name=None,\n",
    "        model_params=model_params,\n",
    "        verbose=False\n",
    "    )\n",
    "    return np.mean(scores) - np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7829261550269685"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",                \n",
    "        \"seed\": 42,\n",
    "        'lambda_l1': 0,\n",
    "        'lambda_l2': 0.002,\n",
    "        'num_leaves': 154,\n",
    "        'feature_fraction': 0.66,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 0,\n",
    "        'min_child_samples': 11,\n",
    "        \"num_class\": 3,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"../../models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"lightgbm_classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ADMSK/fazavyalo2/centralbankai/.venv/lib/python3.8/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/ADMSK/fazavyalo2/centralbankai/.venv/lib/python3.8/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.002, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002\n",
      "[LightGBM] [Warning] feature_fraction is set=0.66, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.66\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "0 it: 53 score: 0.878370155485197\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.002, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002\n",
      "[LightGBM] [Warning] feature_fraction is set=0.66, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.66\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ADMSK/fazavyalo2/centralbankai/.venv/lib/python3.8/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/ADMSK/fazavyalo2/centralbankai/.venv/lib/python3.8/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 it: 64 score: 0.832846924720776\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.002, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002\n",
      "[LightGBM] [Warning] feature_fraction is set=0.66, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.66\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ADMSK/fazavyalo2/centralbankai/.venv/lib/python3.8/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/ADMSK/fazavyalo2/centralbankai/.venv/lib/python3.8/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 it: 36 score: 0.78743789290907\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.002, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002\n",
      "[LightGBM] [Warning] feature_fraction is set=0.66, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.66\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ADMSK/fazavyalo2/centralbankai/.venv/lib/python3.8/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/ADMSK/fazavyalo2/centralbankai/.venv/lib/python3.8/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 it: 54 score: 0.8733058249128277\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.002, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002\n",
      "[LightGBM] [Warning] feature_fraction is set=0.66, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.66\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ADMSK/fazavyalo2/centralbankai/.venv/lib/python3.8/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/ADMSK/fazavyalo2/centralbankai/.venv/lib/python3.8/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 it: 35 score: 0.7515519612516507\n"
     ]
    }
   ],
   "source": [
    "preds, scores = base_cv(\n",
    "    train,\n",
    "    target,\n",
    "    train_features,\n",
    "    cat_features=feats_cat,\n",
    "    model_folder=model_folder,\n",
    "    model_name=model_name,\n",
    "    model_params=model_params,\n",
    "    n_folds=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8247025518559041"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04908866336068601"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligthgbm_classifier = CVModel(os.path.join(model_folder, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_folder, model_name, f\"{model_name}.dill\"), \"wb\") as stream:\n",
    "    dill.dump(ligthgbm_classifier, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
