{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/train_prep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../../data/test_prep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content',\n",
       " 'service',\n",
       " 'priority',\n",
       " 'status',\n",
       " 'group',\n",
       " 'dt_deadline',\n",
       " 'dt_query',\n",
       " 'type_query',\n",
       " 'type_final',\n",
       " 'solution',\n",
       " 'type_reclassification',\n",
       " 'dt_recovery',\n",
       " 'dt_close',\n",
       " 'criticality',\n",
       " 'impact',\n",
       " 'system',\n",
       " 'place']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_cat = [\n",
    "    'service',\n",
    "    'priority',\n",
    "    'status',\n",
    "    'group',\n",
    "    'type_query',\n",
    "    'criticality',\n",
    "    'impact',\n",
    "    'system',\n",
    "    'place'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = feats_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../configs/features.json\", \"w\") as stream:\n",
    "    features = {\n",
    "        \"all_feat\": train_features,\n",
    "        \"feats_numeric\": [],\n",
    "        \"feats_cat\": feats_cat\n",
    "    }\n",
    "    json.dump(features, stream, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"type_reclassification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = lambda *args: f1_score(*args, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index().rename(columns={\"index\": \"ID\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in feats_cat:\n",
    "    le = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=np.nan)\n",
    "    train[feat] = le.fit_transform(train[feat].values.reshape(-1, 1))\n",
    "    with open(f\"../../objects/encoders/{feat}_enc.dill\", \"wb\") as stream:\n",
    "        dill.dump(le, stream)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"num_leaves\": 32,\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"subsample\": 0.8,\n",
    "    \"subsample_freq\": 1,\n",
    "    \"min_child_samples\": 300,\n",
    "    \"n_jobs\": 10,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"num_class\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"../../models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_cv(\n",
    "    train,\n",
    "    target,\n",
    "    train_features,\n",
    "    cat_features=None,\n",
    "    random_state=42,\n",
    "    n_folds=5,\n",
    "    model_folder=\"models\",\n",
    "    model_name=\"model\",\n",
    "    model_params=None\n",
    "):\n",
    "    cat_feats_ind = [i for i, j in enumerate(train_features) if j in cat_features]\n",
    "    model_params[\"categorical_column\"] = cat_feats_ind\n",
    "    skf = StratifiedKFold(n_splits=n_folds, random_state=random_state, shuffle=True)\n",
    "    preds = []\n",
    "    scores = []\n",
    "    for i, (train_idx, test_idx) in enumerate(skf.split(train[train_features], train[target])):\n",
    "        X_train, y_train = train[train_features].iloc[train_idx], train[target].iloc[train_idx]\n",
    "        X_test, y_test = train[train_features].iloc[test_idx], train[target].iloc[test_idx]\n",
    "        model = lgb.LGBMModel(**model_params)\n",
    "        e_stop = round(5 / model.get_params()['learning_rate'])\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=(X_test, y_test), \n",
    "            early_stopping_rounds=e_stop,\n",
    "            eval_metric=model.metric,\n",
    "            verbose=False\n",
    "        )\n",
    "        model.booster_.save_model(os.path.join(model_folder, model_name, f\"fold_{i}.model\",))\n",
    "        fold_preds = model.predict(X_test)\n",
    "        fold_labels = np.argmax(fold_preds, axis=1)\n",
    "        fold_score = metric(y_test, fold_labels)\n",
    "        preds.append(fold_preds)\n",
    "        scores.append(fold_score)\n",
    "        print(\n",
    "            i,\n",
    "            \"it:\", model.best_iteration_,\n",
    "            \"score:\", fold_score\n",
    "        )\n",
    "    return preds, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVModel():\n",
    "    import numpy as np\n",
    "    def __init__(self, models_folder, num_class=3):\n",
    "        from os import listdir\n",
    "        import lightgbm\n",
    "        model_files = [f for f in listdir(models_folder) if '.model' in f]\n",
    "\n",
    "        self.models = []\n",
    "        for model_file in model_files:             \n",
    "            self.models.append(lightgbm.Booster(model_file=os.path.join(models_folder, model_file), params={'n_jobs':1}))\n",
    "        self.num_class = num_class\n",
    "\n",
    "    def predict(self, Y):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        prediction = np.zeros((Y.shape[0], self.num_class))\n",
    "        for model in self.models:\n",
    "\n",
    "            if(isinstance(Y, pd.DataFrame)):\n",
    "                prediction += model.predict(Y[model.feature_name()])\n",
    "            else:\n",
    "                prediction += model.predict(Y)\n",
    "\n",
    "        return prediction / len(self.models)\n",
    "    \n",
    "    def predict_labels(self, Y):\n",
    "        predictions = self.predict(Y)\n",
    "        labels = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ADMSK/fazavyalo2/hack_cb_sb/venv/lib/python3.8/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/ADMSK/fazavyalo2/hack_cb_sb/venv/lib/python3.8/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 it: 182 score: 0.8523727707045516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ADMSK/fazavyalo2/hack_cb_sb/venv/lib/python3.8/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/ADMSK/fazavyalo2/hack_cb_sb/venv/lib/python3.8/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 it: 168 score: 0.815735984962676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ADMSK/fazavyalo2/hack_cb_sb/venv/lib/python3.8/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/ADMSK/fazavyalo2/hack_cb_sb/venv/lib/python3.8/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 it: 91 score: 0.7887840188254555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ADMSK/fazavyalo2/hack_cb_sb/venv/lib/python3.8/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/ADMSK/fazavyalo2/hack_cb_sb/venv/lib/python3.8/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 it: 171 score: 0.8623136861416597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ADMSK/fazavyalo2/hack_cb_sb/venv/lib/python3.8/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/ADMSK/fazavyalo2/hack_cb_sb/venv/lib/python3.8/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 it: 140 score: 0.7405696336881032\n"
     ]
    }
   ],
   "source": [
    "preds, scores = base_cv(\n",
    "    train,\n",
    "    target,\n",
    "    train_features,\n",
    "    cat_features=feats_cat,\n",
    "    model_folder=model_folder,\n",
    "    model_name=\"baseline\",\n",
    "    model_params=model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8119552188644892"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = CVModel(os.path.join(model_folder, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../models/baseline'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(model_folder, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<lightgbm.basic.Booster at 0x7fff9d1cae80>,\n",
       " <lightgbm.basic.Booster at 0x7fff9d186c40>,\n",
       " <lightgbm.basic.Booster at 0x7fff9d733cd0>,\n",
       " <lightgbm.basic.Booster at 0x7fff982ca7c0>,\n",
       " <lightgbm.basic.Booster at 0x7fff9d1860d0>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../models/baseline/baseline_model.dill\", \"wb\") as stream:\n",
    "    dill.dump(baseline_model, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
